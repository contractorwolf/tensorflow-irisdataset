{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Iris-Estimator-Tensorflow-Basics.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/contractorwolf/tensorflow-irisdataset/blob/master/Colab_Iris_Estimator_Tensorflow_Basics.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "m5dNqx-6J2uz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 1. Setup libraries for Machine Learning "
      ]
    },
    {
      "metadata": {
        "id": "c8ik1WG_J2u1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The first step is to import all the libaries that will be needed to parse and explore the data"
      ]
    },
    {
      "metadata": {
        "id": "HpTxLCTUJ2u1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3fc9d84a-0b23-4935-8ca0-9c2151866f5d"
      },
      "cell_type": "code",
      "source": [
        "# IMPORT LIBRARIES (must be installed via pip)\n",
        "# ----------------------------------------------------------------------------\n",
        "\n",
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "import numpy as np              # linear algebra\n",
        "import pandas as pd             # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt # plotting\n",
        "import seaborn as sns           # plotting\n",
        "import tensorflow as tf         # machine learning\n",
        "\n",
        "\n",
        "# ML libraries \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# tell jupyter notebook to diplay plotted data inline\n",
        "%matplotlib inline \n",
        "\n",
        "# SET LOCAL VARIABLES\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# define local file for training data with features and labels\n",
        "csv_file = 'iris.csv'\n",
        "\n",
        "# define feature columns for input feature data \n",
        "prediction_feature_columns = ['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']\n",
        "\n",
        "# path to save the model for future training or tensorflow serving\n",
        "#model_path = 'models/temp/iris'\n",
        "\n",
        "# verify version of tensorflow, should be 1.4+ to use new Estimators features\n",
        "print('TENSORFLOW VERSION: ' + tf.__version__)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TENSORFLOW VERSION: 1.9.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lSk915j7QM2x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eljPJiw_KNhf",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "76dcdd2a-0fcf-457c-fefa-4ba03a8550f8"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4c9694fa-4e0f-49fd-a067-c52a57dfdb19\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-4c9694fa-4e0f-49fd-a067-c52a57dfdb19\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving iris.csv to iris.csv\n",
            "User uploaded file \"iris.csv\" with length 5107 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5y4_fYuCknVs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "8vI34mHIJ2u8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2. Import Dataset from local CSV file"
      ]
    },
    {
      "metadata": {
        "id": "mqNEwqMbJ2u8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You will first need to load your raw data from a local CSV file, and you should attempt to output the columns after each step for verification.  "
      ]
    },
    {
      "metadata": {
        "id": "T6p0KjnAJ2u-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "eeea2552-4588-40b6-c24c-8f84f6efa1a3"
      },
      "cell_type": "code",
      "source": [
        "# get full dataset from local CSV file\n",
        "df = pd.read_csv(csv_file)\n",
        "df.head()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
              "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
              "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
              "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
              "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
              "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "vMI_g7eIJ2vC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#df['SepalLengthCm'].hist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0_5QNGhvJ2vG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#df.plot(kind=\"scatter\", x=\"SepalLengthCm\",y=\"SepalWidthCm\", c=['blue','green','red'], s=100, alpha=.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_LRMocLgJ2vJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#df.plot(kind=\"scatter\", x=\"PetalLengthCm\",y=\"PetalWidthCm\", c=['blue','green','red'], s=100, alpha=.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_3l_3bPSJ2vN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3. Clean up the Dataset"
      ]
    },
    {
      "metadata": {
        "id": "AU8pZ7DJJ2vO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. eliminate noise in data (remove columns not tied to the label)\n",
        "2. make values numeric (remove strings with numeric or hash values)\n",
        "3. randomize order (removes order bias)\n",
        "4. scale data (scaled according to the data, for training and prediction)"
      ]
    },
    {
      "metadata": {
        "id": "h7f1yYRnJ2vP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "a1c28a43-f9d0-4c52-cb04-37c953a9306c"
      },
      "cell_type": "code",
      "source": [
        "# drop unnecessary 'Id' column from the dataset, doesnt help predict the label\n",
        "df.drop('Id', inplace=True, axis=1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zk4iDTKhJ2vS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "baa2a2d8-b4aa-4bdf-cf5d-421565accabf"
      },
      "cell_type": "code",
      "source": [
        "# ALWAYS randomize sample\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.5</td>\n",
              "      <td>2.3</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.3</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.7</td>\n",
              "      <td>2.8</td>\n",
              "      <td>6.7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.8</td>\n",
              "      <td>2.7</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.3</td>\n",
              "      <td>2.9</td>\n",
              "      <td>6.3</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm         Species\n",
              "0            4.5           2.3            1.3           0.3     Iris-setosa\n",
              "1            6.5           3.0            5.2           2.0  Iris-virginica\n",
              "2            7.7           2.8            6.7           2.0  Iris-virginica\n",
              "3            5.8           2.7            5.1           1.9  Iris-virginica\n",
              "4            7.3           2.9            6.3           1.8  Iris-virginica"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "IpK22J8aJ2vV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5a133424-c772-4121-a0fe-3805aa537c6b"
      },
      "cell_type": "code",
      "source": [
        "# label encode the string label: Species\n",
        "# it should be a numeric value, instead of a string value\n",
        "# to do: use one-hot encoder instead of label encoder\n",
        "le = LabelEncoder()\n",
        "df.Species = le.fit_transform(df.Species)\n",
        "\n",
        "# show the cleaned dataset\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.5</td>\n",
              "      <td>2.3</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.7</td>\n",
              "      <td>2.8</td>\n",
              "      <td>6.7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.8</td>\n",
              "      <td>2.7</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.3</td>\n",
              "      <td>2.9</td>\n",
              "      <td>6.3</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
              "0            4.5           2.3            1.3           0.3        0\n",
              "1            6.5           3.0            5.2           2.0        2\n",
              "2            7.7           2.8            6.7           2.0        2\n",
              "3            5.8           2.7            5.1           1.9        2\n",
              "4            7.3           2.9            6.3           1.8        2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "t1LfxiGGJ2vZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "8c145668-8c43-4e44-b1e9-945fc3e4ab88"
      },
      "cell_type": "code",
      "source": [
        "# set just the label column to y for the train_test_split()\n",
        "data_label = df.Species\n",
        "data_label.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    2\n",
              "2    2\n",
              "3    2\n",
              "4    2\n",
              "Name: Species, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "0-FDxUiCJ2vd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "612f2fef-4aac-4e48-c7c0-39daa384a68d"
      },
      "cell_type": "code",
      "source": [
        "# remove the species column so that you can scale the rest of the values\n",
        "# the values are already stored in y variable\n",
        "# *** convert this to X values here, for clarity?\n",
        "data_features = df.drop('Species', inplace=False, axis=1)\n",
        "data_features.head()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.5</td>\n",
              "      <td>2.3</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.7</td>\n",
              "      <td>2.8</td>\n",
              "      <td>6.7</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.8</td>\n",
              "      <td>2.7</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.3</td>\n",
              "      <td>2.9</td>\n",
              "      <td>6.3</td>\n",
              "      <td>1.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
              "0            4.5           2.3            1.3           0.3\n",
              "1            6.5           3.0            5.2           2.0\n",
              "2            7.7           2.8            6.7           2.0\n",
              "3            5.8           2.7            5.1           1.9\n",
              "4            7.3           2.9            6.3           1.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "5w98bJylW8Oo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8694c755-c972-4031-af80-e98b4126cff4"
      },
      "cell_type": "code",
      "source": [
        "# scale data for better results\n",
        "# so that columns with larger values dont get weighed more\n",
        "# example: age change of 40 years (significant) vs income change of $40 (not significant)\n",
        "\n",
        "sc = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
        "scaled_features=pd.DataFrame(sc.fit_transform(data_features), columns=list(data_features.columns))\n",
        "scaled_features.head() \n",
        "# THIS IS A DATAFRAME"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.627688</td>\n",
              "      <td>-1.744778</td>\n",
              "      <td>-1.398138</td>\n",
              "      <td>-1.181504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.795669</td>\n",
              "      <td>-0.124958</td>\n",
              "      <td>0.819624</td>\n",
              "      <td>1.053537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.249683</td>\n",
              "      <td>-0.587764</td>\n",
              "      <td>1.672610</td>\n",
              "      <td>1.053537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.052506</td>\n",
              "      <td>-0.819166</td>\n",
              "      <td>0.762759</td>\n",
              "      <td>0.922064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.765012</td>\n",
              "      <td>-0.356361</td>\n",
              "      <td>1.445147</td>\n",
              "      <td>0.790591</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
              "0      -1.627688     -1.744778      -1.398138     -1.181504\n",
              "1       0.795669     -0.124958       0.819624      1.053537\n",
              "2       2.249683     -0.587764       1.672610      1.053537\n",
              "3      -0.052506     -0.819166       0.762759      0.922064\n",
              "4       1.765012     -0.356361       1.445147      0.790591"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "p51PQ8A6J2vv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "0d74c89d-b539-4015-9530-8bb9393922f2"
      },
      "cell_type": "code",
      "source": [
        "# do a 70/30 split of the data into a train_x and train_y (70% for training) \n",
        "# and a test_x and test_y (30% for validation) \n",
        "# X is a DATAFRAME of scaled features\n",
        "# y is a SERIES of labels\n",
        "train_x, test_x, train_y, test_y = train_test_split(scaled_features, data_label, test_size=0.30, random_state=42)\n",
        " "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tUbz90hVJ2v1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 4. Create Feature Columns List for Classifier"
      ]
    },
    {
      "metadata": {
        "id": "CqwJ8iYHJ2v2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e3aed137-0f10-42d3-d7e8-f07f8a0d5375"
      },
      "cell_type": "code",
      "source": [
        "# Feature columns describe how to use the input.\n",
        "# you need to define the name and type for each column of your training data\n",
        "my_feature_columns = []\n",
        "\n",
        "# numeric coulmns\n",
        "my_feature_columns.append(tf.feature_column.numeric_column(key='SepalLengthCm'));\n",
        "my_feature_columns.append(tf.feature_column.numeric_column(key='SepalWidthCm'));\n",
        "my_feature_columns.append(tf.feature_column.numeric_column(key='PetalLengthCm'));\n",
        "my_feature_columns.append(tf.feature_column.numeric_column(key='PetalWidthCm')); \n",
        "\n",
        "# other column types\n",
        "# hashed strings or categorical features\n",
        "\n",
        "# example:\n",
        "# state = tf.feature_column.categorical_column_with_hash_bucket('state',100) \n",
        "# pick the right size for your data\n",
        "\n",
        "list(my_feature_columns)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[_NumericColumn(key='SepalLengthCm', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
              " _NumericColumn(key='SepalWidthCm', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
              " _NumericColumn(key='PetalLengthCm', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
              " _NumericColumn(key='PetalWidthCm', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "SJflO5T5J2v4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 5. Create Classifier from Feature Column list"
      ]
    },
    {
      "metadata": {
        "id": "decvimqcJ2v5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "d3a8a226-58db-4934-98fe-9f931618b35e"
      },
      "cell_type": "code",
      "source": [
        "# Build 3 hidden layer DNN with 10, 10, 10 units respectively\n",
        "# uses feature column types defined in the previous step\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "    # feature columns defined in the prev step\n",
        "    feature_columns=my_feature_columns,\n",
        "    # three hidden layers of 10 nodes each.\n",
        "    hidden_units=[10, 10, 10],\n",
        "    # model must choose between the 3 classes in dataset\n",
        "    n_classes=data_label.nunique()#,\n",
        "    # save the model to a folder when run, reuse the same way\n",
        "    #model_dir=model_path\n",
        ")\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp7mc5935r\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp7mc5935r', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9c9ad0d0b8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8qS3psyqJ2v8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "b2826403-cfc3-473f-d5ce-c81c69c7f7b3"
      },
      "cell_type": "code",
      "source": [
        "# setup the train input function using the train_x and train_y datasource\n",
        "train_input_fn = tf.estimator.inputs.pandas_input_fn(train_x, y=pd.DataFrame(train_y), num_epochs=500, shuffle=True)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NTa7GIbJJ2v-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 6. Train Classifier"
      ]
    },
    {
      "metadata": {
        "id": "198sym5wJ2v_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "9d3a0444-5196-42be-cb01-913e69e9e40d"
      },
      "cell_type": "code",
      "source": [
        "# this is where training actually occurs, this will be a long running process on large datasets\n",
        "classifier.train(input_fn=train_input_fn)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp7mc5935r/model.ckpt.\n",
            "INFO:tensorflow:loss = 130.38316, step = 1\n",
            "INFO:tensorflow:global_step/sec: 311.778\n",
            "INFO:tensorflow:loss = 3.4718587, step = 101 (0.326 sec)\n",
            "INFO:tensorflow:global_step/sec: 384.122\n",
            "INFO:tensorflow:loss = 3.4746926, step = 201 (0.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 384.73\n",
            "INFO:tensorflow:loss = 2.7547812, step = 301 (0.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 376.359\n",
            "INFO:tensorflow:loss = 1.9434569, step = 401 (0.265 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 411 into /tmp/tmp7mc5935r/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.15746832.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x7f9c9ad6aac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "09ZbCw-CJ2wB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 7. Test classifier with the 30% split data"
      ]
    },
    {
      "metadata": {
        "id": "776Gq2fKJ2wC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "75d373df-e8c2-4ad2-ccd4-cab932b823b4"
      },
      "cell_type": "code",
      "source": [
        "# validate the model using the x_test values to get a prediction for each one\n",
        "# then you can compare the predicted values against the known values in test_y\n",
        "# which will give you an accuracy score in percentage\n",
        "\n",
        "# load 30% test data from split\n",
        "test_input_fn = tf.estimator.inputs.pandas_input_fn(test_x, num_epochs=1, shuffle=False)\n",
        "\n",
        "# make predictions\n",
        "test_result = list(classifier.predict(input_fn=test_input_fn))\n",
        "\n",
        "# display raw results\n",
        "# print(test_result)\n",
        "\n",
        "# build an array with just the predicted species (label encoded values) \n",
        "# filtering out all other prediction response data\n",
        "predicted_y = []\n",
        "for each in test_result:\n",
        "    predicted_y.append(each['class_ids'][0])\n",
        "\n",
        "print('')\n",
        "    \n",
        "# compare the predicted scores on the test data against the actual test_y values\n",
        "# with both a confusion matrix and an accuracy score\n",
        "print('OVERALL ACCURACY:')\n",
        "print(accuracy_score(test_y, predicted_y))\n",
        "\n",
        "print('')\n",
        "\n",
        "print('CONFUSION MATRIX:')\n",
        "print(confusion_matrix(test_y, predicted_y))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp7mc5935r/model.ckpt-411\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "OVERALL ACCURACY:\n",
            "0.9555555555555556\n",
            "\n",
            "CONFUSION MATRIX:\n",
            "[[12  0  0]\n",
            " [ 0 13  0]\n",
            " [ 0  2 18]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EcNWrmAnJ2wM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 8. Predict with new data records "
      ]
    },
    {
      "metadata": {
        "id": "YmG688XqJ2wM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "11993328-850a-4fc7-f107-9326b3aa3afe"
      },
      "cell_type": "code",
      "source": [
        "# test using single records (real world values)\n",
        "# one Iris-setosa, one Iris-versicolor\n",
        "new_records = pd.DataFrame([\n",
        "    [5.1, 3.5, 1.4, 0.2],  # first value to predict\n",
        "    [5.7, 2.8, 4.1, 1.3]], # second value to predict\n",
        "    columns=prediction_feature_columns)\n",
        "    #SepalLengthCm, SepalWidthCm, PetalLengthCm, PetalWidthCm\n",
        "    # 5.1, 3.5, 1.4, 0.2 : 0 (Iris-setosa)\n",
        "    # 5.7, 2.8, 4.1, 1.3 : 1 (Iris-versicolor)\n",
        "\n",
        "\n",
        "# show dataframe for new predictions, prior to scaling\n",
        "print(new_records.columns)\n",
        "\n",
        "\n",
        "print('')\n",
        "\n",
        "# these values must be scaled, to match what is used in the model\n",
        "scaled_new_records = pd.DataFrame(sc.transform(new_records),columns=list(new_records.columns))\n",
        "\n",
        "\n",
        "# predict using the model to get a prediction for each item passed\n",
        "prediction_input_fn = tf.estimator.inputs.pandas_input_fn(scaled_new_records, num_epochs=1, shuffle=False)\n",
        "\n",
        "prediction_result = list(classifier.predict(input_fn=prediction_input_fn))\n",
        "print('')\n",
        "\n",
        "print(prediction_result)\n",
        "\n",
        "\n",
        "# for each of the results\n",
        "i = 0\n",
        "for each in prediction_result:\n",
        "    # print the values used in the prediction\n",
        "    print(new_records.iloc[[i]])\n",
        "    \n",
        "    # print the transformed label-encoded value\n",
        "    print('*** PREDICTION: ' + str(each['class_ids'][0]) + ' (Label Decoded: ' + str(le.inverse_transform(each['class_ids'][0]))+ ')')\n",
        "    print('')\n",
        "    \n",
        "    # go to next row\n",
        "    i = i + 1\n",
        "    \n",
        "#-1.870024, -0.124958, -1.511870, -1.444450 : 0\n",
        "# 1.522676, -0.124958, 1.217684, 1.185010 : 1"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm'], dtype='object')\n",
            "\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp7mc5935r/model.ckpt-411\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "\n",
            "[{'logits': array([ 20.921272,   8.266466, -14.795893], dtype=float32), 'probabilities': array([9.9999678e-01, 3.1921709e-06, 3.0777389e-16], dtype=float32), 'class_ids': array([0]), 'classes': array([b'0'], dtype=object)}, {'logits': array([-3.651794 ,  4.5749416, -3.8476481], dtype=float32), 'probabilities': array([2.6727750e-04, 9.9951303e-01, 2.1973740e-04], dtype=float32), 'class_ids': array([1]), 'classes': array([b'1'], dtype=object)}]\n",
            "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
            "0            5.1           3.5            1.4           0.2\n",
            "*** PREDICTION: 0 (Label Decoded: Iris-setosa)\n",
            "\n",
            "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
            "1            5.7           2.8            4.1           1.3\n",
            "*** PREDICTION: 1 (Label Decoded: Iris-versicolor)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "paMciWrzJ2wZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 9. Save Model for Tensorflow Serving"
      ]
    },
    {
      "metadata": {
        "id": "hzU_9dopJ2wa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "2bfd1286-d242-4919-d8b9-6e471680286c"
      },
      "cell_type": "code",
      "source": [
        "export_dir=\"serving/models/iris/\"\n",
        "\n",
        "feature_spec = tf.feature_column.make_parse_example_spec(my_feature_columns)\n",
        "\n",
        "input_receiver_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\n",
        "\n",
        "classifier.export_savedmodel(export_dir, input_receiver_fn, as_text=False) "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: ['serving_default', 'classification']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp7mc5935r/model.ckpt-411\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: serving/models/iris/temp-b'1530333560'/saved_model.pb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'serving/models/iris/1530333560'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "tUEzK77lJ2wd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 10. Make predictions from the saved DNNClassifier model"
      ]
    },
    {
      "metadata": {
        "id": "PimNE_IrJ2we",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/jeffcarp/example-save-and-load-a-tensorflow-model"
      ]
    },
    {
      "metadata": {
        "id": "CCI0D4mmJ2we",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "302e6522-e744-42a7-c521-74cc8dcb9077"
      },
      "cell_type": "code",
      "source": [
        "# this should load the model from the last saved in the model_dir\n",
        "# so everything it needs should be included below\n",
        "\n",
        "# input column names\n",
        "columns_names = ['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']\n",
        "\n",
        "# where the model was last saved \n",
        "model_path = 'models/temp/iris' \n",
        "\n",
        "# define columns in model using the column_names list\n",
        "# Feature columns describe how to use the input.\n",
        "# you need to define the name and type for each column of your training data\n",
        "hardcoded_feature_columns = []\n",
        "\n",
        "# numeric coulmns\n",
        "hardcoded_feature_columns.append(tf.feature_column.numeric_column(key='SepalLengthCm'));\n",
        "hardcoded_feature_columns.append(tf.feature_column.numeric_column(key='SepalWidthCm'));\n",
        "hardcoded_feature_columns.append(tf.feature_column.numeric_column(key='PetalLengthCm'));\n",
        "hardcoded_feature_columns.append(tf.feature_column.numeric_column(key='PetalWidthCm'));   \n",
        "\n",
        "#hardcoded_feature_columns = []\n",
        "#for key in columns_names:\n",
        "#    hardcoded_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
        "#    print(key)\n",
        "\n",
        "# create a classifier using the defined columns and the pre-defined model\n",
        "saved_estimator = tf.estimator.DNNClassifier(\n",
        "    # feature column array of tf.feature_column types, defined in the prev step\n",
        "    feature_columns=hardcoded_feature_columns,\n",
        "    # Two hidden layers of 10 nodes each.\n",
        "    hidden_units=[10, 10, 10],\n",
        "    # The model must choose between 3 classes.\n",
        "    n_classes=3,\n",
        "    # use saved model from folder\n",
        "    model_dir=model_path\n",
        ")\n",
        "\n",
        "# test using single records (2 real world values)\n",
        "# one Iris-setosa, one Iris-versicolor\n",
        "records_to_predict = pd.DataFrame([\n",
        "    [5.1, 3.5, 1.4, 0.2], # first records features\n",
        "    [5.7, 2.8, 4.1, 1.3]],# second record features\n",
        "    columns=columns_names)# defined column names\n",
        " \n",
        "# these values must be scaled, to match what is used in the model\n",
        "scaled_records_to_predict = pd.DataFrame(sc.transform(records_to_predict), columns=list(records_to_predict.columns))\n",
        "\n",
        "# predict using the model to get a prediction for each item passed\n",
        "saved_prediction_input_fn = tf.estimator.inputs.pandas_input_fn(scaled_records_to_predict, num_epochs=1, shuffle=False)\n",
        "\n",
        "# make predictions and store as a list\n",
        "saved_prediction_result = list(saved_estimator.predict(input_fn=saved_prediction_input_fn))\n",
        "\n",
        "# output prediction values\n",
        "saved_prediction_result\n",
        "\n",
        "#SepalLengthCm, SepalWidthCm, PetalLengthCm, PetalWidthCm\n",
        "#-1.870024, -0.124958, -1.511870, -1.444450 : 0\n",
        "# 1.522676, -0.124958, 1.217684, 1.185010 : 1\n",
        "#estimator_from_file = load_estimator_model('models/iris/1520662093')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'models/temp/iris', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9c97c2a358>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Could not find trained model in model_dir: models/temp/iris, running initialization to predict.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'class_ids': array([1]),\n",
              "  'classes': array([b'1'], dtype=object),\n",
              "  'logits': array([-0.02224503,  0.1289943 , -0.04613251], dtype=float32),\n",
              "  'probabilities': array([0.31850475, 0.37050864, 0.31098664], dtype=float32)},\n",
              " {'class_ids': array([0]),\n",
              "  'classes': array([b'0'], dtype=object),\n",
              "  'logits': array([0.10730875, 0.08063169, 0.02800731], dtype=float32),\n",
              "  'probabilities': array([0.3451326 , 0.33604717, 0.31882018], dtype=float32)}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "wrEzMQTRJ2wi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# END"
      ]
    },
    {
      "metadata": {
        "id": "_hGv5uTKJ2wi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Just testing features and note below this line, not part of main execution"
      ]
    },
    {
      "metadata": {
        "id": "LxdMw3FtJ2wj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}